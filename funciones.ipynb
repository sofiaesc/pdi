{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import imutils\n",
    "import SimpleITK as sitk\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, FloatSlider, RadioButtons, Checkbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para subir imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen = cv.imread('/imagenes/imagen.jpg', cv.IMREAD_GRAYSCALE)\n",
    "imagen_grises = cv.cvtColor(imagen, cv.COLOR_BGR2GRAY)\n",
    "_,imagen_bin = cv.threshold(imagen_grises,150,255,cv.THRESH_BINARY_INV) # tambien THRESH_BINARY sin INV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicar máscara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(imagen.shape, dtype=np.uint8)   # dtype: 'int8', bool, float, tener en cuenta el tipo de dato al realizar las operaciones\n",
    "imagen_masked = cv.bitwise_and(imagen,mask)     # and entre imagen y máscara\n",
    "imagen_masked2 = cv.bitwise_and(imagen,imagen,mask=mask)         # se hace el AND sólo en los px definidos por la máscara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umbralizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umbralBinario(img,umbral):\n",
    "    _, img_umbralizada = cv.threshold(img, umbral, 255, cv.THRESH_BINARY)\n",
    "    return img_umbralizada\n",
    "\n",
    "def umbralAdaptativo(img,maximo,tamanio_bloque,c):\n",
    "    return cv.adaptiveThreshold(img,maximo, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, tamanio_bloque, c);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfil de intensidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFIL DE INTENSIDAD PARA PUNTO DE UNA IMAGEN\n",
    "x=200\n",
    "y=200\n",
    "i = imagen[x,y]\n",
    "\n",
    "print(f\"Intensidad en el punto ({x},{y}): {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFIL DE INTENSIDAD PARA FILA DE UNA IMAGEN\n",
    "fila=200\n",
    "fig,ax = plt.subplots(1,2)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(16)\n",
    "ax[0].imshow(imagen,cmap='gray')\n",
    "ax[0].plot([0,imagen.shape[1]],[fila,fila])\n",
    "ax[1].plot(imagen[fila,:])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFIL DE INTENSIDAD PARA COLUMNA DE UNA IMAGEN\n",
    "columna=200\n",
    "fig,ax = plt.subplots(1,2, figsize=(16,4))\n",
    "ax[0].imshow(imagen,cmap='gray')\n",
    "ax[0].plot([columna,columna],[imagen.shape[0],0])\n",
    "ax[1].plot(imagen[:,columna])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAFICO PERFIL DE INTENSIDAD PARA ROI (REGION DE INTERÉS) DE UNA IMAGEN\n",
    "x = 100\n",
    "y = 100\n",
    "w = 50\n",
    "h = 100\n",
    "roi = imagen[y:y+h,x:x+w]\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(6,4))\n",
    "intensity_profile_hor = np.mean(roi, axis=0)  # promedio horizontal\n",
    "ax[0].plot(intensity_profile_hor)\n",
    "\n",
    "intensity_profile_ver = np.mean(roi, axis=1)  # promedio vertical\n",
    "ax[1].plot(intensity_profile_ver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código para cambiar de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, G, R = cv.split(imagen)\n",
    "imagen = cv.merge([R,G,B])\n",
    "\n",
    "image_RGB = cv.cvtColor(imagen, cv.COLOR_RGB2BGR)\n",
    "image_BGR = cv.cvtColor(imagen, cv.COLOR_BGR2RGB)\n",
    "\n",
    "image_HSV = cv.cvtColor(imagen, cv.COLOR_BGR2HSV)\n",
    "image_BGR = cv.cvtColor(imagen, cv.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGR_a_HSI(image):\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    # Obtener R, G, B\n",
    "    B, G, R = cv.split(image)\n",
    "\n",
    "    # Calcular Intensidad como promedio de R, G, y B\n",
    "    I = (R + G + B) / 3.0\n",
    "\n",
    "    # Calcular Saturación como 1 - m/I\n",
    "    min_BGR = np.min([R, G, B], axis=0)\n",
    "    S = 1 - (3.0 * min_BGR) / (R + G + B + 1e-6)\n",
    "\n",
    "    # Calculas Tono\n",
    "    num = 0.5 * ((R - G) + (R - B))\n",
    "    den = np.sqrt((R - G)**2 + (R - B) * (G - B))\n",
    "    theta = np.arccos(np.clip(num / (den + 1e-6), -1.0, 1.0))\n",
    "    H = theta.copy()\n",
    "    H[B > G] = 2 * np.pi - H[B > G]\n",
    "    H = H / (2 * np.pi)\n",
    "\n",
    "    # Combinar los canales H, S, I en una sola imagen\n",
    "    hsi_image = np.zeros_like(image)\n",
    "    hsi_image[:, :, 0] = H\n",
    "    hsi_image[:, :, 1] = S\n",
    "    hsi_image[:, :, 2] = I\n",
    "\n",
    "    return hsi_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSI_a_RGB(hsi_image):\n",
    "    # Obtener H, S, I\n",
    "    H, S, I = hsi_image[:, :, 0], hsi_image[:, :, 1], hsi_image[:, :, 2]\n",
    "\n",
    "    rgb_image = np.zeros_like(hsi_image)\n",
    "    for x in range(hsi_image.shape[0]):  # Por cada pixel\n",
    "        for y in range(hsi_image.shape[1]):\n",
    "            h = H[x, y] * 2 * np.pi  # Convertir H de [0, 1] a [0, 2*pi]\n",
    "            s = S[x, y]\n",
    "            i = I[x, y]\n",
    "\n",
    "            if h >= 0 and h < 2 * np.pi / 3:\n",
    "                b = i * (1 - s)\n",
    "                r = i * (1 + (s * np.cos(h)) / np.cos(np.pi / 3 - h))\n",
    "                g = 3 * i - (r + b)\n",
    "            elif h >= 2 * np.pi / 3 and h < 4 * np.pi / 3:\n",
    "                h = h - 2 * np.pi / 3\n",
    "                r = i * (1 - s)\n",
    "                g = i * (1 + (s * np.cos(h)) / np.cos(np.pi / 3 - h))\n",
    "                b = 3 * i - (r + g)\n",
    "            else:\n",
    "                h = h - 4 * np.pi / 3\n",
    "                g = i * (1 - s)\n",
    "                b = i * (1 + (s * np.cos(h)) / np.cos(np.pi / 3 - h))\n",
    "                r = 3 * i - (g + b)\n",
    "\n",
    "            # Mergeo los canales calculados, clipeo a [0,1] para la salida\n",
    "            rgb_image[x, y, 0] = np.clip(r, 0, 1)\n",
    "            rgb_image[x, y, 1] = np.clip(g, 0, 1)\n",
    "            rgb_image[x, y, 2] = np.clip(b, 0, 1)\n",
    "\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complemento_color(img_original):\n",
    "    # Convertir la imagen a HSV\n",
    "    img_hsv = cv.cvtColor(img_original, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Copiar la imagen original\n",
    "    img_complemento = img_hsv.copy()\n",
    "\n",
    "    # Calcular el complemento del color para cada píxel\n",
    "    H, S, V = cv.split(img_complemento)\n",
    "\n",
    "    for i in range(H.shape[0]):\n",
    "        for j in range(H.shape[1]):\n",
    "            H[i,j] = (H[i,j] + 90)%180\n",
    "\n",
    "    # Convertir la imagen de vuelta a RGB para visualización\n",
    "    img_complemento = cv.merge([H,S,V])\n",
    "    img_complemento_RGB = cv.cvtColor(img_complemento, cv.COLOR_HSV2RGB)\n",
    "\n",
    "    return img_complemento_RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LUT(a, c, r=[0,256]):         # por default de 0 a 255, si le paso parámetro hace en un tramo específico\n",
    "    r = np.arange(r[0],r[1],1)    # arma vector con paso 1 para aplicar TL punto a punto\n",
    "    s = np.multiply(r,a) + c      # TL\n",
    "    s = np.where(s>255,255,s)   # mayor que 255: 255\n",
    "    s = np.where(s<0,0,s)       # menor que 0: 0\n",
    "    return s\n",
    "\n",
    "def LUT_tramos(tramos):\n",
    "    s = np.arange(0,256,1)  # inicializo formato de salida\n",
    "    for tramo in tramos:    # para cada tramo que definí tengo: [ganancia, offset, ini, fin]\n",
    "      s[tramo[2]:tramo[3]] = LUT(tramo[0],tramo[1],[tramo[2],tramo[3]])  # uso función general que armé antes\n",
    "    return s\n",
    "\n",
    "def t_log():\n",
    "  r = np.arange(256)\n",
    "  s = np.log10(1+r)\n",
    "  return s\n",
    "# mapeo_log = t_log()\n",
    "# salida_log = mapeo_log[imagen[:]]\n",
    "\n",
    "def t_pow(gamma):\n",
    "    r = np.arange(256)/255.0  # normalizo para aplicar potencia\n",
    "    s = pow(r,gamma)          # aplico potencia\n",
    "    return s*255.0            # devuelvo al rango 0:255\n",
    "#mapeo_pow = t_pow(gamma)\n",
    "#salida_pow = mapeo_pow[imagen[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suma(imagenes):\n",
    "  salida = imagenes.sum(axis=0)              # sumo\n",
    "  salida[:] = salida[:]/imagenes.shape[0]    # normalizo\n",
    "  return salida\n",
    "\n",
    "def diferencia(img1,img2):\n",
    "  salida = img1-img2\n",
    "  salida[:] = (salida[:] + 255)/2                     # método 1\n",
    "  # salida[:] = (salida[:] - np.min(salida))/255      # método 2\n",
    "  return salida\n",
    "\n",
    "def multiplicacion(img,mascara):\n",
    "  return np.multiply(img,mascara)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma(imagen,mascara=None):\n",
    "    return cv.calcHist([imagen], [0], mascara, [256], [0,256])\n",
    "\n",
    "def ecualizarHistograma(imagen):\n",
    "    return cv.equalizeHist(imagen)\n",
    "\n",
    "def claheHist(imagen):\n",
    "    clahe = cv.createCLAHE(clipLimit=20.0, tileGridSize=(16,16))\n",
    "    return clahe.apply(imagen)\n",
    "\n",
    "def correlacionHisto(imagen1,imagen2):\n",
    "    hist1 = cv.calcHist([imagen1], [0], None, [256], [0, 256])\n",
    "    hist2 = cv.calcHist([imagen2], [0], None, [256], [0, 256])\n",
    "    return cv.compareHist(hist1, hist2, cv.HISTCMP_CORREL)\n",
    "\n",
    "def ecualizacion_RGB(imagen): # recibe imagen en bgr\n",
    "  imagen_RGB = cv.cvtColor(imagen, cv.COLOR_BGR2RGB)\n",
    "  r, g, b = cv.split(imagen_RGB)             # obtengo canales por separado\n",
    "  r_eq = cv.equalizeHist(r)                  # histogramas de cada canal\n",
    "  g_eq = cv.equalizeHist(g)\n",
    "  b_eq = cv.equalizeHist(b)\n",
    "  imagen_eq = cv.merge([r_eq, g_eq, b_eq])   # mergeo histogramas en la imagen\n",
    "  return imagen_eq  # retorna imagen en rgb\n",
    "\n",
    "def ecualizacion_HSV(imagen): # recibe imagen en bgr\n",
    "  imagen_HSV = cv.cvtColor(imagen, cv.COLOR_BGR2HSV)\n",
    "  h, s, v = cv.split(imagen_HSV)            # obtengo canales por separado\n",
    "  v_eq = cv.equalizeHist(v)                 # ecualizo histograma en V\n",
    "  imagen_eq = cv.merge([h,s,v_eq])          # mergeo los valores orignales de h y s con el histograma de v ecualizado.\n",
    "  imagen_eq_rgb = cv.cvtColor(imagen_eq, cv.COLOR_HSV2RGB)   # retorna imagen en rgb\n",
    "  return imagen_eq_rgb\n",
    "\n",
    "def ecualizacion_HSI(imagen): # recibe imagen en bgr\n",
    "  imagen_HSI = BGR_a_HSI(imagen)\n",
    "  h, s, i = cv.split(imagen_HSI)        # obtengo canales por separado\n",
    "  i_uint8 = (i * 255).astype(np.uint8)\n",
    "  i_eq = cv.equalizeHist(i_uint8)       # ecualizo I\n",
    "  i_eq = i_eq.astype(np.float32) / 255.0\n",
    "  imagen_eq = cv.merge([h,s,i_eq])      # mergeo los valores orignales de h y s con el histograma de i ecualizado.\n",
    "  imagen_eq_rgb = HSI_a_RGB(imagen_eq)\n",
    "  return imagen_eq_rgb  # retorna imagen en rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propiedades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_propiedades(histograma): # calculo todas las propiedades para un histograma\n",
    "    histograma_norm = histograma.ravel()/histograma.sum()  # aplano el vector y normalizo\n",
    "\n",
    "    media = np.sum(histograma_norm * np.arange(256))\n",
    "    varianza = np.sum(histograma_norm * ((np.arange(256) - media) ** 2))\n",
    "    asimetria = np.sum(histograma_norm * ((np.arange(256) - media) ** 3)) / (varianza ** (3/2))\n",
    "    energia = np.sum(histograma_norm ** 2)\n",
    "    entropia = -np.sum(histograma_norm * np.log2(histograma_norm + 1e-7)) # agrego 1e-7 para que no divida por 0\n",
    "    return media, varianza, asimetria, energia, entropia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtroMascara(imagen,mask):\n",
    "    return cv.filter2D(imagen,-1,mask)\n",
    "\n",
    "# filtro pasa-bajo:\n",
    "def filtroBox(imagen,kernel_size):\n",
    "    return cv.boxFilter(imagen,-1,kernel_size,cv.BORDER_ISOLATED )\n",
    "\n",
    "def filtroGausiano(imagen,kernel_size,sigma_x,sigma_y):\n",
    "    return cv.GaussianBlur(imagen, kernel_size, sigma_x, sigma_y)\n",
    "\n",
    "def filtroMedia(imagen, kernel_size):\n",
    "    return cv.medianBlur(imagen, kernel_size)\n",
    "\n",
    "# KERNEL POSTIIVO QUE SUMA 1\n",
    "# PESOS TODOS IGUALES (promediadores -> img borrosa)\n",
    "mask1 = np.array([[1/9, 1/9, 1/9],\n",
    "                  [1/9, 1/9, 1/9],   # 1 + 1 + 1 + 1 - 3 = 1\n",
    "                  [1/9, 1/9, 1/9]])\n",
    "# PESOS DESIGUALES\n",
    "mask2 = np.array([[0, 1/8, 0],\n",
    "                  [1/8, 1/2, 1/8],   # 1 + 1 + 1 + 1 - 3 = 1\n",
    "                  [0, 1/8, 0]])\n",
    "\n",
    "# filtro pasa-alto:\n",
    "# KERNEL POS Y NEG QUE SUMA 1 (no altera bajas frec)\n",
    "mask1 = np.array([[0, 1, 0],\n",
    "                  [1, -3, 1],   # 1 + 1 + 1 + 1 - 3 = 1\n",
    "                  [0, 1, 0]])\n",
    "mask2 = np.array([[-1, -2, -1],\n",
    "                  [0, 1, 0],    # 1 - 1 - 2 - 1 + 1 + 2 + 1 = 1\n",
    "                  [1, 2, 1]])\n",
    "# KERNEL POS Y NEG QUE SUMA 0 (elimina bajas frec)\n",
    "mask3 = np.array([[1, 1, 1],\n",
    "                  [1, -8, 1],\n",
    "                  [1, 1, 1]])\n",
    "mask4 = np.array([[-1, -2, -1],\n",
    "                  [0, 0, 0],\n",
    "                  [1, 2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentacion_rgb(img,roi,R):\n",
    "    # obtenemos información de la roi para generar máscara\n",
    "    BGR_roi = cv.split(roi)\n",
    "    maxB = np.argmax(np.histogram(BGR_roi[0],np.arange(256))[0])  # obtenemos valor más frecuente de rojo\n",
    "    maxG = np.argmax(np.histogram(BGR_roi[1],np.arange(256))[0])  # valor más frecuente de verde\n",
    "    maxR = np.argmax(np.histogram(BGR_roi[2],np.arange(256))[0])  # valor más frecuente de azul\n",
    "\n",
    "    # generar máscara:\n",
    "    H,W,_ = img.shape\n",
    "    maskBGR = np.zeros((H,W),np.uint8)\n",
    "\n",
    "    for i in range(H):  # recorremos píxel a píxel\n",
    "        for j in range(W):\n",
    "            if ((maxB - img[i][j][0])**2 + (maxG - img[i][j][1])**2 + (maxR - img[i][j][2])**2) <= R**2: # si los valores de rojo, verde y azul del píxel i,j\n",
    "                                                                                                         # tienen una distancia euclidea menor a R con los\n",
    "                                                                                                         # valores más frecuentes de la ROI, me interesa.\n",
    "                maskBGR[i][j]=255 # le pongo valor 255 a la máscara en ese píxel, si no entra acá ese píxel queda en 0 y va a descartarlo cunado aplique la máscara.\n",
    "    return maskBGR\n",
    "\n",
    "#maskBGR = segmentacion_rgb(futbol,roi,R=93)\n",
    "#futbol_segm_bgr = cv.bitwise_and(futbol,futbol,mask=maskBGR)\n",
    "\n",
    "def segmentacion_hsv(img,roi,deltaH,deltaS):\n",
    "    # obtenemos los canales de la imagen y de la ROI.\n",
    "    HSV = cv.split(cv.cvtColor(roi, cv.COLOR_BGR2HSV))\n",
    "    HSV_img = cv.split(cv.cvtColor(img, cv.COLOR_BGR2HSV))\n",
    "\n",
    "    # buscamos pico del histograma (valor más frecuente) para los dos canales\n",
    "    maxH = np.argmax(np.histogram(HSV[0],np.arange(256))[0])\n",
    "    maxS = np.argmax(np.histogram(HSV[1],np.arange(256))[0])\n",
    "\n",
    "    # generar máscara:\n",
    "    H,W,_ = img.shape\n",
    "    maskHSV = np.zeros((H,W),np.uint8)\n",
    "\n",
    "    for i in np.arange(H):  # recorremos píxel a píxel\n",
    "        for j in np.arange(W):\n",
    "            # hacemos 1 en la máscara sólo a los píxeles cuyos valores de H y S están dentro del rectángulo definido por los límites:\n",
    "            # (maxH - deltaH, maxH + deltaH) en una dimensión correspondiente al hue o tono\n",
    "            # (maxS - deltaS, maxS + deltaS) en la otra dimensión correspondiente a la saturación\n",
    "            if (HSV_img[0][i,j] >= maxH-deltaH) and (HSV_img[0][i,j] <= maxH+deltaH) and (HSV_img[1][i,j] >=maxS-deltaS) and (HSV_img[1][i,j] <=maxS+deltaS):\n",
    "                maskHSV[i,j] = 255\n",
    "    return maskHSV\n",
    "\n",
    "#maskHSV = segmentacion_hsv(futbol,roi,deltaH=18,deltaS=105)\n",
    "#futbol_segm_hsv = cv.bitwise_and(futbol,futbol,mask=maskHSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dft(image):\n",
    "    dft = cv.dft(np.float32(image), flags=cv.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "    magnitude_spectrum = 20 * np.log(cv.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]) + 1e-6) # sumo para q no haga log(0)\n",
    "    return magnitude_spectrum\n",
    "\n",
    "def get_fft(image):\n",
    "    img_fft = np.fft.fft2(image)\n",
    "    img_fft_shift = np.fft.fftshift(img_fft)\n",
    "    magnitude_spectrum = np.abs(img_fft_shift)\n",
    "    # logaritmo para mayor contraste:\n",
    "    log_magnitude_spectrum = np.log(magnitude_spectrum + 1e-6) # sumo epsilon p/ evitar log(0)\n",
    "    return log_magnitude_spectrum\n",
    "\n",
    "def get_mag_phase(imagen):\n",
    "  f = np.fft.fft2(imagen)\n",
    "  fshift = np.fft.fftshift(f)\n",
    "  magnitud = np.abs(fshift)\n",
    "  fase = np.angle(fshift)\n",
    "  return magnitud, fase\n",
    "\n",
    "def ifft(espectro):\n",
    "    imagen=np.fft.fftshift(espectro)\n",
    "    imagen=np.abs(np.fft.ifft2(imagen))\n",
    "    # imagen=np.fft.fftshift(imagen)\n",
    "    imagen=np.real(imagen)\n",
    "    return imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtros frecuenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(image, filter_mask):\n",
    "    dft_shift = get_dft(image)\n",
    "    filtered_dft = dft_shift * filter_mask[:, :, np.newaxis]  # Aplicar filtro\n",
    "    f_ishift = np.fft.ifftshift(filtered_dft)\n",
    "    img_back = cv.idft(f_ishift)\n",
    "    img_back = cv.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n",
    "    img_back = np.clip(img_back / np.max(img_back), 0, 1)  # Normalizar para visualización\n",
    "    return img_back\n",
    "\n",
    "def ideal_low_pass_filter(shape, cutoff_frequency):\n",
    "    rows, cols = shape                                        # Consigue las dimensiones de la imagen\n",
    "    center_row, center_col = rows // 2, cols // 2             # Consigue el centro de la imagen\n",
    "    filter_mask = np.zeros((rows, cols), dtype=np.float32)    # Crea una matriz de igual tamaño que la imagen pero llena de 0s\n",
    "    cv.circle(filter_mask, (center_col, center_row),\n",
    "               cutoff_frequency, 1, thickness=-1)             # Dibuja un circulo de readio \"frecuencia de corte\" en el centro de la imagen\n",
    "    return filter_mask                                        # Retorna la máscara\n",
    "\n",
    "def ideal_high_pass_filter(shape, cutoff_frequency):\n",
    "    rows, cols = shape                                        # Consigue las dimensiones de la imagen\n",
    "    center_row, center_col = rows // 2, cols // 2             # Consigue el centro de la imagen\n",
    "    filter_mask = np.ones((rows, cols), dtype=np.float32)    # Crea una matriz de igual tamaño que la imagen pero llena de 0s\n",
    "    cv.circle(filter_mask, (center_col, center_row),\n",
    "               cutoff_frequency, 0, thickness=-1)             # Dibuja un circulo de readio \"frecuencia de corte\" en el centro de la imagen\n",
    "    return filter_mask                                        # Retorna la máscara\n",
    "\n",
    "def butterworth_low_pass_filter(shape, cutoff_frequency, order):\n",
    "    rows, cols = shape\n",
    "    center_row, center_col = rows // 2, cols // 2\n",
    "    filter_mask = np.zeros((rows, cols), dtype=np.float32)\n",
    "\n",
    "    for u in range(rows):\n",
    "        for v in range(cols):\n",
    "            distance = np.sqrt((u - center_row) ** 2 + (v - center_col) ** 2)           # Calcula la distancia al centro de la imagen D(u,v)\n",
    "            filter_mask[u, v] = 1 / (1 + (distance / cutoff_frequency) ** (2 * order))  # Crea la máscara para Butterwort\n",
    "\n",
    "    return filter_mask\n",
    "\n",
    "def butterworth_high_pass_filter(shape, cutoff_frequency, order):\n",
    "    rows, cols = shape\n",
    "    center_row, center_col = rows // 2, cols // 2\n",
    "    filter_mask = np.zeros((rows, cols), dtype=np.float32)\n",
    "\n",
    "    for u in range(rows):\n",
    "        for v in range(cols):\n",
    "            distance = np.sqrt((u - center_row) ** 2 + (v - center_col) ** 2)                 # Calcula la distancia al centro de la imagen D(u,v)\n",
    "            filter_mask[u, v] = 1 - (1 / (1 + (distance / cutoff_frequency) ** (2 * order)))  # Crea la máscara para Butterwort\n",
    "\n",
    "    return filter_mask\n",
    "\n",
    "def gaussian_low_pass_filter(shape, sigma):\n",
    "    rows, cols = shape\n",
    "    center_row, center_col = rows // 2, cols // 2\n",
    "    filter_mask = np.zeros((rows, cols), dtype=np.float32)\n",
    "\n",
    "    for u in range(rows):\n",
    "        for v in range(cols):\n",
    "            distance = np.sqrt((u - center_row) ** 2 + (v - center_col) ** 2)\n",
    "            filter_mask[u, v] = np.exp(-(distance**2 / (2 * sigma**2)))\n",
    "\n",
    "    return filter_mask\n",
    "\n",
    "def gaussian_high_pass_filter(shape, sigma):\n",
    "    rows, cols = shape\n",
    "    center_row, center_col = rows // 2, cols // 2\n",
    "    filter_mask = np.zeros((rows, cols), dtype=np.float32)\n",
    "\n",
    "    for u in range(rows):\n",
    "        for v in range(cols):\n",
    "            distance = np.sqrt((u - center_row) ** 2 + (v - center_col) ** 2)\n",
    "            filter_mask[u, v] = 1 - np.exp(-(distance**2 / (2 * sigma**2)))\n",
    "\n",
    "    return filter_mask\n",
    "\n",
    "# Filtro homomórfico: claros más oscuros y oscuros más claros\n",
    "def homomorphic_filter(img, rl=0.05, rh=0.5, c=25, orden=2):\n",
    "    rows, cols = img.shape\n",
    "\n",
    "    # USAMOS FILTRO GAUSSIANO:\n",
    "    x = np.linspace(-1, 1, cols)\n",
    "    y = np.linspace(-1, 1, rows)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    d = np.sqrt(X**2 + Y**2)\n",
    "    mask = (rh - rl) * (1 - np.exp(-c * d**orden)) + rl\n",
    "\n",
    "    # APLICAR FILTRO:\n",
    "    img_log = np.log1p(img)\n",
    "    img_fft = np.fft.fft2(img_log)\n",
    "    img_fft_shift = np.fft.fftshift(img_fft)\n",
    "    img_fft_filt = img_fft_shift * mask\n",
    "    img_filt = np.real(np.fft.ifft2(np.fft.ifftshift(img_fft_filt)))\n",
    "    img_exp = np.expm1(img_filt)\n",
    "    img_norm = cv.normalize(img_exp, None, 0, 255, cv.NORM_MINMAX)\n",
    "\n",
    "    img_filtered = np.uint8(img_norm)\n",
    "\n",
    "    return img_filtered\n",
    "\n",
    "def AltaPotencia(pasaAltos, A):\n",
    "  altaPotencia = (A-1)+pasaAltos\n",
    "  return altaPotencia\n",
    "\n",
    "def EnfasisAltaFrecuencia(a,b,mascaraPA):\n",
    "  MascaraEAF = a+b*mascaraPA\n",
    "  return MascaraEAF\n",
    "\n",
    "def AltaFrecuenciaimg(img,A,imgPA):\n",
    "  img_AF = (A-1)*img+imgPA\n",
    "  return img_AF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angulo = 20\n",
    "imagen_rotada = imutils.rotate(imagen, angulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_to_angle(original_image, image_to_rotate):\n",
    "\n",
    "    # Aplicar la transformada de Fourier a las imágenes\n",
    "    fft_original = np.real(np.fft.fft2(original_image)).astype(np.uint8)\n",
    "    fft_to_rotate = np.real(np.fft.fft2(image_to_rotate)).astype(np.uint8)\n",
    "\n",
    "    # Calcular el espectro de potencia\n",
    "    power_spectrum_original = np.abs(fft_original) ** 2\n",
    "    power_spectrum_to_rotate = np.abs(fft_to_rotate) ** 2\n",
    "\n",
    "    # Calcular la correlación cruzada entre los espectros de potencia\n",
    "    cross_correlation = cv.matchTemplate(power_spectrum_original, power_spectrum_to_rotate, cv.TM_CCORR_NORMED)\n",
    "\n",
    "    # Encontrar la posición del valor máximo en la matriz de correlación cruzada\n",
    "    _, max_val, _, max_loc = cv.minMaxLoc(cross_correlation)\n",
    "\n",
    "    # Calcular el desplazamiento en píxeles desde la posición central hasta la posición del valor máximo\n",
    "    rows, cols = cross_correlation.shape\n",
    "    displacement = np.array(max_loc) - np.array((cols // 2, rows // 2))\n",
    "\n",
    "    # Calcular el ángulo de rotación correspondiente al desplazamiento\n",
    "    angle = np.degrees(np.arctan2(displacement[1], displacement[0]))\n",
    "\n",
    "    return (180 + angle)  # como el ángulo obtenido en el dominio de la frecuencia está entre [-180,180], sumo 180 para tener [0,360]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ruido_gaussiano(image, mean=100, stdev=10):\n",
    "    gauss = np.random.normal(mean, stdev, image.shape)\n",
    "    noise_image = image + gauss\n",
    "    return np.uint8(noise_image)\n",
    "\n",
    "def ruido_uniforme(image, low=-5, high=5):\n",
    "    uniform = np.random.uniform(low, high, image.shape)\n",
    "    noise_image = image + uniform\n",
    "    return np.uint8(noise_image)\n",
    "\n",
    "def ruido_impulsivo(image, salt_prob=0.01, pepper_prob=0.01):\n",
    "    noise_image = image.copy()\n",
    "    probs = np.random.random(noise_image.shape[:2])\n",
    "    noise_image[probs < salt_prob] = 255\n",
    "    noise_image[probs > 1 - pepper_prob] = 0\n",
    "    return np.uint8(noise_image)\n",
    "\n",
    "def ruido_exponencial(image, scale=25):\n",
    "    exponencial = np.random.exponential(scale, image.shape)\n",
    "    noise_image = image + exponencial\n",
    "    return np.uint8(noise_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtros de medias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_mean_filter(image, filter_size):\n",
    "    im_H, im_W = image.shape\n",
    "    padsize = (filter_size - 1) // 2 # Calcular el tamaño del padding necesario\n",
    "\n",
    "    # Añadir padding a la imagen para manejar los bordes\n",
    "    # cv.copyMakeBorder se usa para añadir bordes constantes de valor 1 alrededor de la imagen\n",
    "    im_p = cv.copyMakeBorder(np.copy(image), padsize, padsize, padsize, padsize, cv.BORDER_CONSTANT, value=1).astype(np.float64)\n",
    "\n",
    "    im_f_mg = np.zeros(image.shape)\n",
    "\n",
    "    # Aplicar el filtro de media geométrica\n",
    "    for i in range(im_H):\n",
    "        for j in range(im_W):\n",
    "            window = im_p[i:i + filter_size, j:j + filter_size] # Extraer la ventana de la imagen con padding\n",
    "            product = np.prod(window)\n",
    "            im_f_mg[i, j] = product ** (1 / (filter_size ** 2))\n",
    "\n",
    "    return np.uint8(im_f_mg) # Convertir la imagen filtrada al tipo uint8 para asegurar que los valores sean válidos en el rango [0, 255]\n",
    "\n",
    "\n",
    "def contrarmonic_filter(image, ksize, Q): # función recibe imagen, tamaño de la ventana del filtro (debe ser impar) y Q es orden del filtro contra-armónico\n",
    "    im_H, im_W = image.shape\n",
    "    padsize = (ksize - 1) // 2 # Calcular el tamaño del padding necesario\n",
    "\n",
    "    # Añadir padding a la imagen para manejar los bordes\n",
    "    # cv.copyMakeBorder se usa para añadir bordes de ceros alrededor de la imagen\n",
    "    im_p = cv.copyMakeBorder(np.copy(image), padsize, padsize, padsize, padsize, cv.BORDER_CONSTANT, value=0).astype(np.float64)\n",
    "\n",
    "    im_f_mch = np.zeros(image.shape)\n",
    "\n",
    "    # Aplicar el filtro contrarmónico\n",
    "    for i in range(im_H):\n",
    "        for j in range(im_W):\n",
    "            window = im_p[i:i + ksize, j:j + ksize] # Extraer la ventana de la imagen con padding\n",
    "            numerator = np.sum(window ** (Q + 1))\n",
    "            denominator = np.sum(window ** Q)\n",
    "\n",
    "            # Calcular el valor filtrado, manejando divisiones por cero\n",
    "            im_f_mch[i, j] = numerator / (denominator + 1e-6)\n",
    "\n",
    "    return np.uint8(im_f_mch) # Convertir la imagen filtrada al tipo uint8 para valores válidos en el rango [0, 255]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtros de orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtro_mediana(img,kernel_size = 3):\n",
    "  output = cv.medianBlur(img,kernel_size)\n",
    "  return np.uint8(output)\n",
    "\n",
    "def filtro_punto_medio(image, kernel_size = 3):\n",
    "  output = np.zeros(image.shape)\n",
    "  H, W = image.shape\n",
    "  padsize = (kernel_size-1)//2\n",
    "  im_p = cv.copyMakeBorder(np.copy(image), *[padsize]*4, cv.BORDER_CONSTANT,0).astype(np.float64)\n",
    "\n",
    "  for i in range(H):\n",
    "      for j in range(W):\n",
    "          vMin, vMax = cv.minMaxLoc(im_p[i:i+kernel_size,j:j+kernel_size])[0:2]\n",
    "          output[i, j] = (vMin+vMax)/2\n",
    "  return np.uint8(output)\n",
    "\n",
    "def filtro_media_alfa(img, kernel_size = 3, d = 8):\n",
    "  output = np.zeros(img.shape)\n",
    "  im_H, im_W = img.shape\n",
    "  padsize = (kernel_size-1)//2\n",
    "  im_p = cv.copyMakeBorder(np.copy(img), *[padsize]*4, cv.BORDER_CONSTANT,0).astype(np.float64)\n",
    "\n",
    "  for i in range(im_H):\n",
    "      for j in range(im_W):\n",
    "          S = np.sort(im_p[i:i+kernel_size,j:j+kernel_size].flatten())\n",
    "          S = S[d//2:S.shape[0]-d//2]\n",
    "          output[i, j] = np.sum(S)/S.shape[0]\n",
    "\n",
    "  return np.uint8(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de bordes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewitt_edge_detection(image):\n",
    "    prewitt_x = cv.filter2D(image, -1, np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]))\n",
    "    prewitt_y = cv.filter2D(image, -1, np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]]))\n",
    "    prewitt_edges = cv.bitwise_or(prewitt_x, prewitt_y)\n",
    "    _, binary_edges = cv.threshold(prewitt_edges, 50, 255, cv.THRESH_BINARY)\n",
    "    return binary_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para normalizar y actualizar la imagen con los nuevos parámetros\n",
    "def update_sobel(ddepth, dx, ksize):\n",
    "    global image\n",
    "    edges = cv.Sobel(image, ddepth, dx, 1-dx, ksize=ksize)\n",
    "    plt.imshow(edges, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.title('Sobel Edges')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Crear controles interactivos\n",
    "ddepth_widget = RadioButtons(options=[('CV_8U', cv.CV_8U), ('CV_64F', cv.CV_64F)], description='ddepth:')\n",
    "dx_widget = RadioButtons(options=[('dx', 1), ('dy', 0)], description='Derivative:')\n",
    "ksize_widget = IntSlider(min=-1, max=31, step=2, value=3, description='ksize:')\n",
    "\n",
    "# Llamar a la función interact para generar la interfaz interactiva\n",
    "interact(update_sobel, ddepth=ddepth_widget, dx=dx_widget, ksize=ksize_widget);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para actualizar la imagen con los nuevos parámetros\n",
    "def update_laplacian(ksize):\n",
    "    global image\n",
    "    edges_laplacian = cv.Laplacian(image, cv.CV_64F, ksize=ksize)\n",
    "    plt.imshow(edges_laplacian, cmap='gray')\n",
    "    plt.title('Bordes Laplacianos')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Crear control deslizante interactivo\n",
    "ksize_slider = IntSlider(min=1, max=31, step=2, value=3, description='Tamaño del kernel')\n",
    "\n",
    "# Llamar a la función interact para generar la interfaz interactiva\n",
    "interact(update_laplacian, ksize=ksize_slider);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para actualizar la imagen con los nuevos parámetros\n",
    "def update_canny(threshold1, threshold2, l2gradient):\n",
    "    global image\n",
    "    # imagen_suavizada = cv.GaussianBlur(imagen_gris, (5, 5), 0)  # filtro gaussiano para mejor umbralizado (varía según img)\n",
    "    edges = cv.Canny(image, threshold1, threshold2, L2gradient=bool(l2gradient))\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.title('Bordes Canny')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Crear controles interactivos\n",
    "threshold1_slider = IntSlider(min=0, max=255, value=50, description='Threshold 1:')\n",
    "threshold2_slider = IntSlider(min=0, max=255, value=150, description='Threshold 2:')\n",
    "l2gradient_checkbox = Checkbox(value=False, description='L2gradient')\n",
    "\n",
    "# Llamar a la función interact para generar la interfaz interactiva\n",
    "interact(update_canny, threshold1=threshold1_slider, threshold2=threshold2_slider, l2gradient=l2gradient_checkbox);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.HoughLinesP(\timage, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]]\t)\n",
    "image2 = cv.imread('/content/drive/My Drive/PDI/letras1.tif', cv.IMREAD_GRAYSCALE)\n",
    "# imagen_suavizada = cv.GaussianBlur(imagen_gris, (5, 5), 0)  # filtro gaussiano para mejor umbralizado (varía según img)\n",
    "image2_canny = cv.Canny(image2, 50, 200, None)  #  en documentación: \"Input image should be a binary image, so apply threshold or use canny edge detection before applying hough transform\"\n",
    "\n",
    "def updateHough(set_threshold, set_mintheta, set_maxtheta):\n",
    "  imageHough = cv.cvtColor(image2_canny, cv.COLOR_GRAY2BGR)\n",
    "  lines = cv.HoughLines(image2_canny, rho = 1, theta = np.pi/180, threshold = set_threshold, min_theta = set_mintheta, max_theta = set_maxtheta)\n",
    "\n",
    "  if lines is not None:\n",
    "      for line in lines:\n",
    "          rho, theta = line[0]\n",
    "          cos_theta, sin_theta = np.cos(theta), np.sin(theta)\n",
    "          x0, y0 = rho * cos_theta, rho * sin_theta\n",
    "          x1, y1 = int(x0 + 1000 * (-sin_theta)), int(y0 + 1000 * cos_theta)\n",
    "          x2, y2 = int(x0 - 1000 * (-sin_theta)), int(y0 - 1000 * cos_theta)\n",
    "          cv.line(imageHough, (x1, y1), (x2, y2), (255, 0, 172), 3, cv.LINE_AA)\n",
    "\n",
    "  plt.imshow(imageHough)\n",
    "  plt.title(f'threshold = {set_threshold}, min_theta = {set_mintheta}, max_theta = {set_maxtheta}')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "slider_threshold = IntSlider(min=0, max=200, value=53, description='Threshold:')\n",
    "slider_mintheta = FloatSlider(min=0.0, max=3.14, step=0.01, value=0.0, description='Min Theta:')\n",
    "slider_maxtheta = FloatSlider(min=0.0, max=3.14, step=0.01, value=2.66, description='Max Theta:')\n",
    "\n",
    "# para que los sliders no tiren error (min tiene que ser menor a max sino rompe el HoughLines)\n",
    "def check_theta(change):\n",
    "    if slider_mintheta.value > slider_maxtheta.value:\n",
    "        slider_maxtheta.value = slider_mintheta.value\n",
    "slider_mintheta.observe(check_theta, 'value')\n",
    "slider_maxtheta.observe(check_theta, 'value')\n",
    "\n",
    "interact(updateHough, set_threshold = slider_threshold, set_mintheta = slider_mintheta, set_maxtheta = slider_maxtheta);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.HoughLinesP(\timage, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]]\t)\n",
    "image2 = cv.imread('/content/drive/My Drive/PDI/letras1.tif', cv.IMREAD_GRAYSCALE)\n",
    "#imagen_suavizada = cv.GaussianBlur(imagen_gris, (5, 5), 0)  # filtro gaussiano para mejor umbralizado (varía según img)\n",
    "image2_canny = cv.Canny(image2, 50, 200, None)  #  en documentación: \"Input image should be a binary image, so apply threshold or use canny edge detection before applying hough transform\"\n",
    "\n",
    "def updateHoughP(set_threshold, set_minLength, set_maxGap):\n",
    "  imageHoughP = cv.cvtColor(image2_canny, cv.COLOR_GRAY2BGR)\n",
    "  lines = cv.HoughLinesP(image2_canny, rho = 1, theta = np.pi/180, threshold = set_threshold, minLineLength = set_minLength, maxLineGap = set_maxGap)\n",
    "\n",
    "  if lines is not None:\n",
    "      for line in lines:\n",
    "          l = line[0]\n",
    "          cv.line(imageHoughP, (l[0], l[1]), (l[2], l[3]), (255,0,127,0), 3, cv.LINE_AA)\n",
    "  plt.imshow(imageHoughP)\n",
    "  plt.title(f'threshold = {set_threshold}, minLineLength = {set_minLength}, maxLineGap = {set_maxGap}')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "slider_threshold = IntSlider(min=0, max=200, value=35, description='Threshold:')\n",
    "slider_minLength = IntSlider(min=0, max=200, value=32, description='Min Line Length:')\n",
    "slider_maxGap = IntSlider(min=0, max=200, value=19, description='Max Line Gap:')\n",
    "\n",
    "interact(updateHoughP, set_threshold = slider_threshold, set_minLength = slider_minLength, set_maxGap = slider_maxGap);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sitk = sitk.VectorIndexSelectionCast(sitk.ReadImage('/content/drive/My Drive/PDI/bone.tif'), 0)\n",
    "\n",
    "LOWER = 80                         # umbral mínimo\n",
    "UPPER = 255                        # umbral máximo\n",
    "SEEDLIST = [(230,150),(150,45)]    # semillas (podría ser con click pero...)\n",
    "\n",
    "seg = sitk.ConnectedThreshold(img_sitk, seedList=SEEDLIST, lower=LOWER, upper=UPPER)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(9,9))\n",
    "ax[0].imshow(sitk.GetArrayFromImage(img_sitk),cmap=\"gray\")\n",
    "for seed in SEEDLIST: # grafico las semillas para ver donde las tomé\n",
    "  ax[0].scatter(seed[0],seed[1])\n",
    "ax[1].imshow(sitk.GetArrayFromImage(seg), cmap='gray', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latas = cv.imread('/content/drive/My Drive/PDI/latas.png')\n",
    "latas1 = latas.copy() # salida sin preprocesamiento\n",
    "\n",
    "latas_gray = cv.cvtColor(latas,cv.COLOR_BGR2GRAY)\n",
    "latas_blur = cv.medianBlur(latas_gray,5)\n",
    "circles = cv.HoughCircles(latas_blur, cv.HOUGH_GRADIENT, 1, 250, minRadius=115)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(circles)\n",
    "    for i in circles[0, :]:\n",
    "        cv.circle(latas1, (i[0],i[1]), i[2], (255, 0, 170), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morfología"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE = np.ones((3,3)).astype(np.uint8)    # cuadrado\n",
    "\n",
    "EE = np.zeros((5,5)).astype(np.uint8)   # línea diagonal\n",
    "for i in range(EE.shape[0]):  # pruebo con distintos tamaños de kernel (n,n)\n",
    "  EE[i,EE.shape[0]-1-i] = 255 # hago la diagonal\n",
    "\n",
    "ee_cross = cv.getStructuringElement(cv.MORPH_CROSS,(3,3))\n",
    "ee_rect = cv.getStructuringElement(cv.MORPH_RECT,(3,3))\n",
    "ee_ellipse = cv.getStructuringElement(cv.MORPH_ELLIPSE,(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estrellas = cv.imread(\"drive/MyDrive/PDI/estrellas.jpg\")\n",
    "estrellas_gris = cv.cvtColor(estrellas,cv.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "_,estrellas_binario = cv.threshold(estrellas_gris,130,255,cv.THRESH_BINARY)\n",
    "\n",
    "dst = cv.erode(imagen,EE)\n",
    "dst = cv.dilate(imagen,EE)\n",
    "# Apertura: dilate -> erode\n",
    "# Cierre: erode -> dilate\n",
    "\n",
    "apertura = cv.morphologyEx(tarjeta_binario,cv.MORPH_OPEN,EE, iteration=2)\n",
    "cierre = cv.morphologyEx(tarjeta_binario,cv.MORPH_CLOSE,EE, iteration=2)\n",
    "erosion = cv.morphologyEx(tarjeta_binario,cv.MORPH_ERODE,EE, iteration=2)\n",
    "dilatacion = cv.morphologyEx(tarjeta_binario,cv.MORPH_DILATE,EE, iteration=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
